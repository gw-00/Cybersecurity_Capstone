{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664c7caf",
   "metadata": {},
   "source": [
    "## Data Exploration Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652ae17",
   "metadata": {},
   "source": [
    "## Libary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e621332",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries here\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1bee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filepath to the parquet cleaned dataset\n",
    "PATH = \"../Data/Cleaned/Cleaned_Dataset.parquet\"\n",
    "\n",
    "# scan the parquet file with polars\n",
    "scan = pl.scan_parquet(PATH)\n",
    "\n",
    "# get the dataset schema\n",
    "schema = scan.collect_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6acda",
   "metadata": {},
   "source": [
    "## 1. General Descriptive Statistics\n",
    "\n",
    "This section examines missing values, row and column counts, numeric descriptive statistics, and categorical descriptive statistics for the cleaned dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34fd7c",
   "metadata": {},
   "source": [
    "### 1.1 Get row and column counts of the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf4e942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaned dataset has 21005240 rows and 42 columns.\n"
     ]
    }
   ],
   "source": [
    "# get row counts\n",
    "row_count = scan.select(pl.len()).collect().item()\n",
    "\n",
    "# get column counts\n",
    "col_names = schema.names()\n",
    "col_count = len(col_names)\n",
    "\n",
    "# output the row and column counts\n",
    "print(f\"The cleaned dataset has {row_count} rows and {col_count} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03758f7",
   "metadata": {},
   "source": [
    "### 1.2 Column names and their respective data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb61fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "column",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dtype",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "62c21dca-3586-4253-a5ee-2c4535ae00da",
       "rows": [
        [
         "0",
         "Header_Length",
         "Float32"
        ],
        [
         "1",
         "Protocol_Type",
         "Categorical"
        ],
        [
         "2",
         "Time_To_Live",
         "Float32"
        ],
        [
         "3",
         "Rate",
         "Float32"
        ],
        [
         "4",
         "fin_flag_number",
         "Float32"
        ],
        [
         "5",
         "syn_flag_number",
         "Float32"
        ],
        [
         "6",
         "rst_flag_number",
         "Float32"
        ],
        [
         "7",
         "psh_flag_number",
         "Float32"
        ],
        [
         "8",
         "ack_flag_number",
         "Float32"
        ],
        [
         "9",
         "ece_flag_number",
         "Float32"
        ],
        [
         "10",
         "cwr_flag_number",
         "Float32"
        ],
        [
         "11",
         "ack_count",
         "Int32"
        ],
        [
         "12",
         "syn_count",
         "Int32"
        ],
        [
         "13",
         "fin_count",
         "Int32"
        ],
        [
         "14",
         "rst_count",
         "Int32"
        ],
        [
         "15",
         "HTTP",
         "Float32"
        ],
        [
         "16",
         "HTTPS",
         "Float32"
        ],
        [
         "17",
         "DNS",
         "Float32"
        ],
        [
         "18",
         "Telnet",
         "Float32"
        ],
        [
         "19",
         "SMTP",
         "Float32"
        ],
        [
         "20",
         "SSH",
         "Float32"
        ],
        [
         "21",
         "IRC",
         "Float32"
        ],
        [
         "22",
         "TCP",
         "Float32"
        ],
        [
         "23",
         "UDP",
         "Float32"
        ],
        [
         "24",
         "DHCP",
         "Float32"
        ],
        [
         "25",
         "ARP",
         "Float32"
        ],
        [
         "26",
         "ICMP",
         "Float32"
        ],
        [
         "27",
         "IGMP",
         "Float32"
        ],
        [
         "28",
         "IPv",
         "Float32"
        ],
        [
         "29",
         "LLC",
         "Float32"
        ],
        [
         "30",
         "Tot_sum",
         "Int32"
        ],
        [
         "31",
         "Min",
         "Int32"
        ],
        [
         "32",
         "Max",
         "Int32"
        ],
        [
         "33",
         "AVG",
         "Float32"
        ],
        [
         "34",
         "Std",
         "Float32"
        ],
        [
         "35",
         "Tot_size",
         "Float32"
        ],
        [
         "36",
         "IAT",
         "Float32"
        ],
        [
         "37",
         "Number",
         "Int32"
        ],
        [
         "38",
         "Variance",
         "Float32"
        ],
        [
         "39",
         "Label",
         "Categorical"
        ],
        [
         "40",
         "Label_Family",
         "Categorical"
        ],
        [
         "41",
         "Label_Binary",
         "Int32"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 42
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Header_Length</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Protocol_Type</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time_To_Live</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rate</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fin_flag_number</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>syn_flag_number</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rst_flag_number</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psh_flag_number</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ack_flag_number</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ece_flag_number</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cwr_flag_number</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ack_count</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>syn_count</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fin_count</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rst_count</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HTTP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HTTPS</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DNS</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Telnet</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SMTP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SSH</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IRC</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TCP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UDP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DHCP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ARP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ICMP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IGMP</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>IPv</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLC</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Tot_sum</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Min</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Max</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AVG</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Std</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Tot_size</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>IAT</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Number</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Variance</td>\n",
       "      <td>Float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Label</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Label_Family</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Label_Binary</td>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column        dtype\n",
       "0     Header_Length      Float32\n",
       "1     Protocol_Type  Categorical\n",
       "2      Time_To_Live      Float32\n",
       "3              Rate      Float32\n",
       "4   fin_flag_number      Float32\n",
       "5   syn_flag_number      Float32\n",
       "6   rst_flag_number      Float32\n",
       "7   psh_flag_number      Float32\n",
       "8   ack_flag_number      Float32\n",
       "9   ece_flag_number      Float32\n",
       "10  cwr_flag_number      Float32\n",
       "11        ack_count        Int32\n",
       "12        syn_count        Int32\n",
       "13        fin_count        Int32\n",
       "14        rst_count        Int32\n",
       "15             HTTP      Float32\n",
       "16            HTTPS      Float32\n",
       "17              DNS      Float32\n",
       "18           Telnet      Float32\n",
       "19             SMTP      Float32\n",
       "20              SSH      Float32\n",
       "21              IRC      Float32\n",
       "22              TCP      Float32\n",
       "23              UDP      Float32\n",
       "24             DHCP      Float32\n",
       "25              ARP      Float32\n",
       "26             ICMP      Float32\n",
       "27             IGMP      Float32\n",
       "28              IPv      Float32\n",
       "29              LLC      Float32\n",
       "30          Tot_sum        Int32\n",
       "31              Min        Int32\n",
       "32              Max        Int32\n",
       "33              AVG      Float32\n",
       "34              Std      Float32\n",
       "35         Tot_size      Float32\n",
       "36              IAT      Float32\n",
       "37           Number        Int32\n",
       "38         Variance      Float32\n",
       "39            Label  Categorical\n",
       "40     Label_Family  Categorical\n",
       "41     Label_Binary        Int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_df = pd.DataFrame({\n",
    "    \"column\": col_names,\n",
    "    \"dtype\": [str(schema[name]) for name in col_names]\n",
    "})\n",
    "\n",
    "dtype_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac51e78",
   "metadata": {},
   "source": [
    "### 1.3 Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23274eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "missing_count",
         "rawType": "uint32",
         "type": "integer"
        },
        {
         "name": "missing_pct",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "541b9b72-8699-41be-a0af-94e94b75c8eb",
       "rows": [
        [
         "0",
         "Protocol_Type",
         "3168935",
         "15.086402250105213"
        ],
        [
         "1",
         "Header_Length",
         "0",
         "0.0"
        ],
        [
         "2",
         "Time_To_Live",
         "0",
         "0.0"
        ],
        [
         "3",
         "Rate",
         "0",
         "0.0"
        ],
        [
         "4",
         "fin_flag_number",
         "0",
         "0.0"
        ],
        [
         "5",
         "syn_flag_number",
         "0",
         "0.0"
        ],
        [
         "6",
         "rst_flag_number",
         "0",
         "0.0"
        ],
        [
         "7",
         "psh_flag_number",
         "0",
         "0.0"
        ],
        [
         "8",
         "ack_flag_number",
         "0",
         "0.0"
        ],
        [
         "9",
         "ece_flag_number",
         "0",
         "0.0"
        ],
        [
         "10",
         "cwr_flag_number",
         "0",
         "0.0"
        ],
        [
         "11",
         "ack_count",
         "0",
         "0.0"
        ],
        [
         "12",
         "syn_count",
         "0",
         "0.0"
        ],
        [
         "13",
         "fin_count",
         "0",
         "0.0"
        ],
        [
         "14",
         "rst_count",
         "0",
         "0.0"
        ],
        [
         "15",
         "HTTP",
         "0",
         "0.0"
        ],
        [
         "16",
         "HTTPS",
         "0",
         "0.0"
        ],
        [
         "17",
         "DNS",
         "0",
         "0.0"
        ],
        [
         "18",
         "Telnet",
         "0",
         "0.0"
        ],
        [
         "19",
         "SMTP",
         "0",
         "0.0"
        ],
        [
         "20",
         "SSH",
         "0",
         "0.0"
        ],
        [
         "21",
         "IRC",
         "0",
         "0.0"
        ],
        [
         "22",
         "TCP",
         "0",
         "0.0"
        ],
        [
         "23",
         "UDP",
         "0",
         "0.0"
        ],
        [
         "24",
         "DHCP",
         "0",
         "0.0"
        ],
        [
         "25",
         "ARP",
         "0",
         "0.0"
        ],
        [
         "26",
         "ICMP",
         "0",
         "0.0"
        ],
        [
         "27",
         "IGMP",
         "0",
         "0.0"
        ],
        [
         "28",
         "IPv",
         "0",
         "0.0"
        ],
        [
         "29",
         "LLC",
         "0",
         "0.0"
        ],
        [
         "30",
         "Tot_sum",
         "0",
         "0.0"
        ],
        [
         "31",
         "Min",
         "0",
         "0.0"
        ],
        [
         "32",
         "Max",
         "0",
         "0.0"
        ],
        [
         "33",
         "AVG",
         "0",
         "0.0"
        ],
        [
         "34",
         "Std",
         "0",
         "0.0"
        ],
        [
         "35",
         "Tot_size",
         "0",
         "0.0"
        ],
        [
         "36",
         "IAT",
         "0",
         "0.0"
        ],
        [
         "37",
         "Number",
         "0",
         "0.0"
        ],
        [
         "38",
         "Variance",
         "0",
         "0.0"
        ],
        [
         "39",
         "Label",
         "0",
         "0.0"
        ],
        [
         "40",
         "Label_Family",
         "0",
         "0.0"
        ],
        [
         "41",
         "Label_Binary",
         "0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 42
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Protocol_Type</td>\n",
       "      <td>3168935</td>\n",
       "      <td>15.086402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Header_Length</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time_To_Live</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fin_flag_number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>syn_flag_number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rst_flag_number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psh_flag_number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ack_flag_number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ece_flag_number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cwr_flag_number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ack_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>syn_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fin_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rst_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HTTP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HTTPS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DNS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Telnet</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SMTP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SSH</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IRC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TCP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UDP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DHCP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ARP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ICMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IGMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>IPv</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Tot_sum</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Min</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Max</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AVG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Std</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Tot_size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>IAT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Variance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Label</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Label_Family</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Label_Binary</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  missing_count  missing_pct\n",
       "0     Protocol_Type        3168935    15.086402\n",
       "1     Header_Length              0     0.000000\n",
       "2      Time_To_Live              0     0.000000\n",
       "3              Rate              0     0.000000\n",
       "4   fin_flag_number              0     0.000000\n",
       "5   syn_flag_number              0     0.000000\n",
       "6   rst_flag_number              0     0.000000\n",
       "7   psh_flag_number              0     0.000000\n",
       "8   ack_flag_number              0     0.000000\n",
       "9   ece_flag_number              0     0.000000\n",
       "10  cwr_flag_number              0     0.000000\n",
       "11        ack_count              0     0.000000\n",
       "12        syn_count              0     0.000000\n",
       "13        fin_count              0     0.000000\n",
       "14        rst_count              0     0.000000\n",
       "15             HTTP              0     0.000000\n",
       "16            HTTPS              0     0.000000\n",
       "17              DNS              0     0.000000\n",
       "18           Telnet              0     0.000000\n",
       "19             SMTP              0     0.000000\n",
       "20              SSH              0     0.000000\n",
       "21              IRC              0     0.000000\n",
       "22              TCP              0     0.000000\n",
       "23              UDP              0     0.000000\n",
       "24             DHCP              0     0.000000\n",
       "25              ARP              0     0.000000\n",
       "26             ICMP              0     0.000000\n",
       "27             IGMP              0     0.000000\n",
       "28              IPv              0     0.000000\n",
       "29              LLC              0     0.000000\n",
       "30          Tot_sum              0     0.000000\n",
       "31              Min              0     0.000000\n",
       "32              Max              0     0.000000\n",
       "33              AVG              0     0.000000\n",
       "34              Std              0     0.000000\n",
       "35         Tot_size              0     0.000000\n",
       "36              IAT              0     0.000000\n",
       "37           Number              0     0.000000\n",
       "38         Variance              0     0.000000\n",
       "39            Label              0     0.000000\n",
       "40     Label_Family              0     0.000000\n",
       "41     Label_Binary              0     0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing counts\n",
    "missing_count_df = (\n",
    "    scan\n",
    "    .select([\n",
    "        pl.col(c).null_count().alias(c)\n",
    "        for c in col_names\n",
    "    ])\n",
    "    .collect()\n",
    "    .transpose(include_header=True, header_name=\"feature\")\n",
    ")\n",
    "\n",
    "# Rename the second column (e.g. 'column_0') to 'missing_count'\n",
    "missing_count_df = missing_count_df.rename({\n",
    "    missing_count_df.columns[1]: \"missing_count\"\n",
    "})\n",
    "\n",
    "\n",
    "# Missing percentages\n",
    "missing_pct_df = (\n",
    "    scan\n",
    "    .select([\n",
    "        (pl.col(c).null_count() / pl.len() * 100).alias(c)\n",
    "        for c in col_names\n",
    "    ])\n",
    "    .collect()\n",
    "    .transpose(include_header=True, header_name=\"feature\")\n",
    ")\n",
    "\n",
    "# Rename the second column to 'missing_pct'\n",
    "missing_pct_df = missing_pct_df.rename({\n",
    "    missing_pct_df.columns[1]: \"missing_pct\"\n",
    "})\n",
    "\n",
    "\n",
    "# Combine into a single DataFrame and sort\n",
    "missing_pl = (\n",
    "    missing_count_df\n",
    "    .join(missing_pct_df, on=\"feature\", how=\"inner\")\n",
    "    .sort(\"missing_pct\", descending=True)\n",
    ")\n",
    "\n",
    "missing_df = missing_pl.to_pandas()\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ffc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization for missing features\n",
    "nonzero_missing = missing_df[missing_df[\"missing_count\"] > 0].copy()\n",
    "\n",
    "if not nonzero_missing.empty:\n",
    "    plt.figure(figsize=(8, max(3, 0.3 * len(nonzero_missing))))\n",
    "    sns.barplot(\n",
    "        data=nonzero_missing,\n",
    "        y=\"feature\",\n",
    "        x=\"missing_pct\",\n",
    "        orient=\"h\"\n",
    "    )\n",
    "    plt.xlabel(\"Missing (%)\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(\"Missingness by Feature (Full Dataset)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a41418",
   "metadata": {},
   "source": [
    "### 1.4 Numeric Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the numeric columns using Int32 or Float32 data types\n",
    "numeric_cols = [\n",
    "    name for name in col_names\n",
    "    if schema[name] in {pl.Int32, pl.Float32}]\n",
    "\n",
    "# build aggregate expressions for each numeric column\n",
    "# intiitalize the empty list\n",
    "agg_exprs = []\n",
    "\n",
    "# for loop to append the aggregate expressions for each numeric column\n",
    "for c in numeric_cols:\n",
    "    agg_exprs.extend([\n",
    "        pl.col(c).mean().alias(f\"{c}_mean\"),\n",
    "        pl.col(c).std().alias(f\"{c}_std\"),\n",
    "        pl.col(c).min().alias(f\"{c}_min\"),\n",
    "        pl.col(c).quantile(0.25).alias(f\"{c}_q1\"),\n",
    "        pl.col(c).median().alias(f\"{c}_median\"),\n",
    "        pl.col(c).quantile(0.75).alias(f\"{c}_q3\"),\n",
    "        pl.col(c).max().alias(f\"{c}_max\"),\n",
    "    ])\n",
    "\n",
    "# run a single lazy pass over the full dataset\n",
    "stats_pl = scan.select(agg_exprs).collect()\n",
    "\n",
    "# convert to pandas and reshape to a nicer format\n",
    "stats_df = stats_pl.to_pandas().T\n",
    "stats_df.columns = [\"value\"]\n",
    "\n",
    "# reshape to a wider format\n",
    "rows = []\n",
    "for idx, val in stats_df[\"value\"].items():\n",
    "    feature, stat = idx.rsplit(\"_\", 1)\n",
    "    rows.append([feature, stat, val])\n",
    "\n",
    "wide = pd.DataFrame(rows, columns=[\"feature\", \"stat\", \"value\"])\n",
    "wide_df = wide.pivot(index=\"feature\", columns=\"stat\", values=\"value\")\n",
    "\n",
    "wide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1dc65",
   "metadata": {},
   "source": [
    "We note that the above numeric descriptive statistics dataframe is revealing especially identifying that there is a minimum value for the feature IAT of -0.01781797967851162. This says that there are packets which are arriving before the next packet and is not an artifact of actual network traffic. This will have to be readjusted to clamp negative values to zero or left as is. This occurs as a result of packet capture timestamp jitter which is aknown limitation of CICFlowMeter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87bd24",
   "metadata": {},
   "source": [
    "### 1.5 Categorical Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"Protocol_Type\", \"Label\"]\n",
    "\n",
    "# initialize empty categorical summary dictionary\n",
    "categorical_summary = {}\n",
    "\n",
    "# for loop to compute value counts for each categorical column\n",
    "for col in categorical_cols:\n",
    "    # Compute full value counts for the column using lazy evaluation\n",
    "    value_counts_df = (\n",
    "        scan\n",
    "        .group_by(col)\n",
    "        .len()\n",
    "        .sort(\"len\", descending=True)\n",
    "        .collect()\n",
    "        .to_pandas()\n",
    "        .rename(columns={\"len\": \"count\"})\n",
    "    )\n",
    "    \n",
    "    categorical_summary[col] = value_counts_df\n",
    "\n",
    "# display\n",
    "display(value_counts_df)\n",
    "display(categorical_summary[\"Protocol_Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbfd99",
   "metadata": {},
   "source": [
    "This above categorical descriptive stats combined with the missing values statistics shows that there are 2,814,440 missing Protocol Types, which is roughly ~14% of the cleaned dataset. We may consider dropping the missing values in order to properly clean our dataset for modeling even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    value_counts_df = categorical_summary[col]\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(data=value_counts_df, x=col, y=\"count\")\n",
    "    # Rotate x labels vertically for readability\n",
    "    plt.xticks(rotation=90)\n",
    "    # Format y-axis with comma separators\n",
    "    ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.title(f\"Distribution of {col} (Full Dataset)\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcd49a",
   "metadata": {},
   "source": [
    "## 2. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ed4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our helper histogram function leveraging polars lazy computation\n",
    "def full_histogram(scan, column: str, bins: int = 50):\n",
    "    \"\"\"\n",
    "    Compute histogram bins for a numeric column using the full dataset \n",
    "    (lazy Polars computation), returning a small pandas DataFrame with:\n",
    "    - bin_mid\n",
    "    - count\n",
    "    \"\"\"\n",
    "    # Compute min/max for the full column\n",
    "    min_max = scan.select([\n",
    "        pl.col(column).min().alias(\"min\"),\n",
    "        pl.col(column).max().alias(\"max\")\n",
    "    ]).collect()\n",
    "\n",
    "    col_min = float(min_max[\"min\"][0])\n",
    "    col_max = float(min_max[\"max\"][0])\n",
    "\n",
    "    # avoid invalid bins\n",
    "    if not np.isfinite(col_min) or not np.isfinite(col_max) or col_min == col_max:\n",
    "        return pd.DataFrame({\"bin_mid\": [], \"count\": []})\n",
    "\n",
    "    # Build bin edges\n",
    "    edges = np.linspace(col_min, col_max, bins + 1)\n",
    "\n",
    "    # Cut into bins & count frequencies\n",
    "    hist_df = (\n",
    "        scan\n",
    "        .with_columns([\n",
    "            pl.col(column).cut(breaks=edges).alias(\"bin\")\n",
    "        ])\n",
    "        .group_by(\"bin\")\n",
    "        .len()\n",
    "        .sort(\"bin\")\n",
    "        .collect()\n",
    "        .to_pandas()\n",
    "        .rename(columns={\"len\": \"count\"})\n",
    "    )\n",
    "\n",
    "    # Compute bin midpoints\n",
    "    mids = []\n",
    "    for b in hist_df[\"bin\"]:\n",
    "        # Format: \"[a, b)\"\n",
    "        s = str(b).strip(\"[]()\")\n",
    "        left, right = s.split(\",\")\n",
    "        mids.append((float(left), float(right)))\n",
    "\n",
    "    hist_df[\"bin_mid\"] = [(l + r) / 2 for (l, r) in mids]\n",
    "\n",
    "    return hist_df[[\"bin_mid\", \"count\"]]\n",
    "\n",
    "def plot_univariate_numeric(column: str, bins: int = 50):\n",
    "    \"\"\"\n",
    "    Plot the univariate distribution of a numeric feature using a fully \n",
    "    memory-safe histogram computed over the entire dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    column : str\n",
    "        Name of the numeric column to visualize.\n",
    "    bins : int, default=50\n",
    "        Number of histogram bins used when aggregating the feature.\n",
    "\n",
    "    Description\n",
    "    -----------\n",
    "    This function visualizes the distribution of a numeric variable by using \n",
    "    `full_histogram()`, which computes bin counts lazily with Polars. Unlike \n",
    "    traditional histogram plotting approaches that require loading the entire \n",
    "    column into memory, this method performs aggregation at the Polars \n",
    "    LazyFrame level, making it safe to use on very large datasets (e.g., \n",
    "    20+ million rows).\n",
    "\n",
    "    The returned histogram is a small, aggregated DataFrame containing:\n",
    "        - bin_mid : midpoint of each histogram bin\n",
    "        - count   : number of observations falling within each bin\n",
    "\n",
    "    These aggregated results are then plotted using seaborn for a clean, \n",
    "    readable visualization of the full distribution.\n",
    "    \"\"\"\n",
    "    hist_df = full_histogram(scan, column, bins=bins)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(data=hist_df, x=\"bin_mid\", y=\"count\", color=\"steelblue\")\n",
    "\n",
    "    plt.title(f\"Distribution of {column} (Full Dataset)\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0fbb1",
   "metadata": {},
   "source": [
    "### 2.1 Skewness of Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ae6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract random 200,000 observation sample for skewness analysis\n",
    "SKEW_SAMPLE_N = 200_000\n",
    "# chunk this to keep memory small\n",
    "CHUNK_SIZE = 100_000\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "collected = []\n",
    "\n",
    "start = 0\n",
    "\n",
    "# Loop until we collect 200k total rows\n",
    "while sum(len(df) for df in collected) < SKEW_SAMPLE_N:\n",
    "    chunk = (\n",
    "        scan\n",
    "        .slice(start, CHUNK_SIZE)\n",
    "        .select(numeric_cols)\n",
    "        .collect()\n",
    "        .to_pandas()\n",
    "    )\n",
    "    \n",
    "    # If no more rows, break (failsafe)\n",
    "    if chunk.empty:\n",
    "        break\n",
    "\n",
    "    # Randomly choose ~30% of each chunk\n",
    "    sampled = chunk.sample(frac=0.3, random_state=rng.integers(0, 1e9))\n",
    "    collected.append(sampled)\n",
    "\n",
    "    start += CHUNK_SIZE\n",
    "\n",
    "# Concatenate all chunk samples\n",
    "sample_df = pd.concat(collected, ignore_index=True)\n",
    "\n",
    "# Final trim down to perfect 200,000\n",
    "if len(sample_df) > SKEW_SAMPLE_N:\n",
    "    sample_df = sample_df.sample(n=SKEW_SAMPLE_N, random_state=42)\n",
    "\n",
    "print(\"Final sample size:\", len(sample_df))\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute skewness dataframe\n",
    "\n",
    "skewness_series = sample_df.skew(numeric_only=True)\n",
    "\n",
    "# build skewness dataframe\n",
    "skewness_df = (\n",
    "    skewness_series\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame(name=\"skewness\")\n",
    ")\n",
    "\n",
    "# compute absolute skewness for ordering\n",
    "skewness_df[\"abs_skew\"] = skewness_df[\"skewness\"].abs()\n",
    "\n",
    "# sort by absolute skew (most skewed first)\n",
    "skewness_df = skewness_df.sort_values(\"abs_skew\", ascending=False)\n",
    "\n",
    "skewness_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 6 most skewed features\n",
    "top_skewed_features = skewness_df.index[:6].tolist()\n",
    "\n",
    "for col in top_skewed_features:\n",
    "    print(f\"\\nProcessing feature: {col}\")\n",
    "\n",
    "    # Use the existing 200,000 sample_df\n",
    "    raw_vals = sample_df[col].dropna()\n",
    "\n",
    "    # Log1p transform\n",
    "    log_vals = np.log1p(raw_vals)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "    # RAW\n",
    "    sns.histplot(raw_vals, bins=60, ax=axes[0], color=\"steelblue\")\n",
    "    axes[0].set_title(f\"{col}: Raw (Sampled 200k)\")\n",
    "    axes[0].set_xlabel(col)\n",
    "\n",
    "    # LOG\n",
    "    sns.histplot(log_vals, bins=60, ax=axes[1], color=\"darkorange\")\n",
    "    axes[1].set_title(f\"{col}: log1p (Sampled 200k)\")\n",
    "    axes[1].set_xlabel(f\"log1p({col})\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2584dfb",
   "metadata": {},
   "source": [
    "#### Interpreting the Univariate Distributions for Highly Skewed Features\n",
    "\n",
    "The raw and log-transformed histograms for highly skewed numeric features (e.g., `IAT`, `Telnet`, `SMTP`, `IRC`, `ece_flag_num`, `cwr_flag_num`) appear dominated by a single bar. Although not visually rich, these plots reveal **critical characteristics** of the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. Extreme Sparsity in Network Flow Features\n",
    "Across all highly skewed variables, **over 99% of values are zero or extremely close to zero**. This is typical in IoT network telemetry:\n",
    "\n",
    "- Most flows never trigger certain protocols or flags.  \n",
    "- Inter-arrival times (e.g., `IAT`) are often 0.  \n",
    "- Protocol counters (`SMTP`, `Telnet`, `IRC`, etc.) are rarely activated.  \n",
    "\n",
    "As a result, the first histogram bin (containing near-zero values) captures almost the entire dataset.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. The Dominant Zero Bin\n",
    "Because nearly all values lie at or near zero, the leftmost bin completely dominates the histogram. This causes:\n",
    "\n",
    "- All other bins to appear empty  \n",
    "- The distribution to visually collapse into a single spike  \n",
    "- Very large differences between the dominant bin and the tail  \n",
    "\n",
    "This is a **true reflection of the data**, not a plotting issue.\n",
    "\n",
    "---\n",
    "    \n",
    "##### 3. Why Log Transform Doesn't Change the Shape Much\n",
    "The log transform helps with long-tailed data, but:\n",
    "\n",
    "- `log1p(0) = 0`  \n",
    "- When 99%+ of values are zero, log1p still leaves the same dominant zero spike  \n",
    "- Only the very small fraction of high outliers shift position  \n",
    "\n",
    "Thus, the log1p histogram remains dominated by a single bar.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. These Features Behave Like Sparse Event Counters\n",
    "Instead of behaving like continuous numeric variables, these columns function more like:\n",
    "\n",
    "- **event indicators** (presence vs absence)  \n",
    "- **anomaly spikes**  \n",
    "- **rare protocol activations**  \n",
    "\n",
    "This makes traditional histograms less informative.\n",
    "\n",
    "---\n",
    "\n",
    "##### 5. Better Approaches for Understanding These Features\n",
    "Given the extreme sparsity, more meaningful summaries include:\n",
    "\n",
    "- Zero vs non-zero counts  \n",
    "- Percentile tables (p50, p90, p95, p99, p99.9, max)  \n",
    "- Log-scale boxplots  \n",
    "- Distributions of **non-zero** values only  \n",
    "- Comparing distributions across the `Label` column (malicious vs benign)\n",
    "\n",
    "These provide clearer insight into how these features behave in relation to attack detection.\n",
    "\n",
    "---\n",
    "\n",
    "##### Conclusion for skewness analysis\n",
    "Although the histograms appear visually simple, they accurately reflect that these features are **highly sparse, zero-dominated, and spike-driven**â€”a common pattern in IoT network traffic data. Understanding this structure is essential for guiding appropriate feature engineering and model selection in downstream analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07bce6e",
   "metadata": {},
   "source": [
    "### 2.2 Zero vs. Non-Zero Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc27e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_nonzero_stats = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Compute zero count and non-zero count lazily\n",
    "    result = (\n",
    "        scan\n",
    "        .select([\n",
    "            (pl.col(col) == 0).sum().alias(\"zero_count\"),\n",
    "            (pl.col(col) != 0).sum().alias(\"nonzero_count\")\n",
    "        ])\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    zero_count = int(result[\"zero_count\"][0])\n",
    "    nonzero_count = int(result[\"nonzero_count\"][0])\n",
    "    total = zero_count + nonzero_count\n",
    "\n",
    "    zero_nonzero_stats.append({\n",
    "        \"feature\": col,\n",
    "        \"zero_count\": zero_count,\n",
    "        \"nonzero_count\": nonzero_count,\n",
    "        \"pct_nonzero\": nonzero_count / total * 100\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "zero_nonzero_df = pd.DataFrame(zero_nonzero_stats)\n",
    "\n",
    "# Sort by non-zero percentage (descending)\n",
    "zero_nonzero_df = zero_nonzero_df.sort_values(\"pct_nonzero\", ascending=False)\n",
    "\n",
    "zero_nonzero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of zero vs. non-zero features\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(\n",
    "    data=zero_nonzero_df,\n",
    "    x=\"feature\",\n",
    "    y=\"pct_nonzero\",\n",
    "    color=\"steelblue\"\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Percentage of Non-Zero Values (%)\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.title(\"Non-Zero Frequency Across Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03476d",
   "metadata": {},
   "source": [
    "#### Zero vs Non-Zero Analysis Summary\n",
    "\n",
    "To better understand sparsity patterns in the dataset, we evaluated the percentage of zero and non-zero values for every numeric feature. This revealed several important structural properties of the network traffic:\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. Dense Features (â‰ˆ 100% Non-Zero)\n",
    "Features such as `Rate`, `Number`, `IAT`, `Tot_size`, `AVG`, `Max`, `Min`, and `Tot_sum` show **no zero values at all**.  \n",
    "These represent continuous traffic characteristics (packet counts, sizes, timing aggregates) and exhibit normal numeric behavior suitable for standard scaling and transformation techniques.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Moderately Sparse Features (10%â€“60% Non-Zero)\n",
    "Features like `TCP`, `UDP`, `Std`, `Variance`, `ack_count`, `syn_count`, `psh_flag_number`, and `ICMP` contain a mix of zero and non-zero values.  \n",
    "These features likely capture protocol activity or flow behavior that occurs intermittently.  \n",
    "They may exhibit long-tailed or bursty patterns that require log-scale analysis or special consideration during feature engineering.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Highly Sparse Features (< 5% Non-Zero)\n",
    "Protocol-specific and flag-specific counters (e.g., `SSH`, `IRC`, `Telnet`, `SMTP`, `IGMP`, `ece_flag_number`, `cwr_flag_number`) are **almost always zero**, with non-zero rates below 1%.  \n",
    "This sparsity is expected in IoT network traffic: most flows do not activate these protocols or flags.  \n",
    "These features behave more like **binary indicators** of rare events rather than continuous numeric variables.\n",
    "\n",
    "---\n",
    "\n",
    "##### Key Insight\n",
    "The presence of both dense and highly sparse numeric features suggests a mixture of:\n",
    "\n",
    "- **continuous traffic descriptors**  \n",
    "- **event-driven anomaly counters**  \n",
    "- **rare protocol activations**\n",
    "\n",
    "This explains why raw and log-transformed histograms often collapsed into a single bar: the distributions are dominated by near-zero values.  \n",
    "Understanding this sparsity structure is essential for selecting appropriate transformations, feature encodings, and downstream modeling strategies.\n",
    "\n",
    "---\n",
    "\n",
    "##### Next Steps\n",
    "To complete the univariate numeric analysis, we will generate **percentile summary tables (p50â€“p99.9)** for each feature.  \n",
    "This will help characterize tail behavior, scale differences, and outlier severity across the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c04de8",
   "metadata": {},
   "source": [
    "### 2.3 Percentile Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b146a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [0.50, 0.90, 0.95, 0.99, 0.999]\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Compute stats lazily\n",
    "    result = (\n",
    "        scan\n",
    "        .select([\n",
    "            pl.col(col).min().alias(\"min\"),\n",
    "            pl.col(col).max().alias(\"max\"),\n",
    "            *[\n",
    "                pl.col(col).quantile(q, \"nearest\").alias(f\"p{int(q*1000)/10}\")\n",
    "                for q in percentiles\n",
    "            ]\n",
    "        ])\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    row = {\"feature\": col}\n",
    "    for key in result.columns:\n",
    "        row[key] = float(result[key][0])\n",
    "    \n",
    "    summary_rows.append(row)\n",
    "\n",
    "percentile_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Order columns nicely\n",
    "ordered_cols = [\"feature\", \"min\", \"p50.0\", \"p90.0\", \"p95.0\", \"p99.0\", \"p99.9\", \"max\"]\n",
    "percentile_df = percentile_df[ordered_cols]\n",
    "\n",
    "# Sort by tail severity (p99.9 - median)\n",
    "percentile_df[\"tail_spread\"] = percentile_df[\"p99.9\"] - percentile_df[\"p50.0\"]\n",
    "percentile_df = percentile_df.sort_values(\"tail_spread\", ascending=False)\n",
    "\n",
    "percentile_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba398d74",
   "metadata": {},
   "source": [
    "#### Percentile Summary Table: Interpretation of Numeric Feature Distributions\n",
    "\n",
    "To better understand the distributional structure of numeric featuresâ€”especially those exhibiting heavy tails or extreme sparsityâ€”we computed detailed percentile statistics (p50 â†’ p99.9) for every numeric column. This analysis provides critical insight into feature scale, tail behavior, and the presence of rare but extreme values commonly found in network intrusion datasets.\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. Strong Long-Tail Behavior in Continuous Traffic Features\n",
    "Features such as `Variance`, `Rate`, `Std`, `Tot_sum`, `Min`, and `Max` exhibit **very large differences** between the median (p50) and extreme percentiles (p99 and p99.9).  \n",
    "\n",
    "For example:\n",
    "\n",
    "- **Variance**: p50 â‰ˆ 1.96 â†’ p99.9 â‰ˆ 1,253,775  \n",
    "- **Rate**: p50 â‰ˆ 12,682 â†’ p99.9 â‰ˆ 303,935  \n",
    "- **Std**: p50 â‰ˆ 1.40 â†’ p99.9 â‰ˆ 2,643  \n",
    "\n",
    "These extremely heavy-tailed distributions are expected in high-volume IoT network flows and indicate that a small fraction of connections exhibit dramatically different behavior compared to the majority.  \n",
    "Such variables may benefit from **log transformation**, **robust scaling**, or **winsorization** when used in models sensitive to outliers.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Dense but Highly Variable Aggregation Features\n",
    "Aggregated size and timing metrics such as `Tot_size`, `AVG`, `Time_To_Live`, and `Header_Length` show:\n",
    "\n",
    "- high percentages of non-zero values  \n",
    "- moderate to strong increases from p50 to p99.9  \n",
    "- typical behavior for continuous packet-level metrics  \n",
    "\n",
    "These features are likely **important predictors** due to their broad distribution and variability across flows.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Sparse Event Counters and Protocol Indicators\n",
    "Many protocol or flag-based features (e.g., `ack_count`, `syn_count`, `psh_flag_number`, `UDP`, `ICMP`) show:\n",
    "\n",
    "- **min = p50 = 0**  \n",
    "- small increases by p90/p95  \n",
    "- sharp jumps at p99 or p99.9  \n",
    "\n",
    "This pattern indicates **rare but meaningful spikes**, which align with anomalous or malicious behaviors.  \n",
    "For example:\n",
    "\n",
    "- `ack_count`: p50 = 0 â†’ p99.9 = 100  \n",
    "- `UDP`: p50 = 0 â†’ p99.9 = 2  \n",
    "\n",
    "Even small non-zero values may signal specific types of attacks or protocol misuse.\n",
    "\n",
    "---\n",
    "##### 4. Nearly Binary Features (0 Almost Everywhere)\n",
    "Some features (e.g., `SSH`, `IRC`, `Telnet`, `SMTP`, `IGMP`, `cwr_flag_number`, `ece_flag_number`) remain zero through almost all percentiles, only rising at p99 or p99.9.\n",
    "\n",
    "These essentially behave as **binary indicators**:\n",
    "\n",
    "- 0 = no activity  \n",
    "- >0 = rare protocol activation (often associated with attack traffic)\n",
    "\n",
    "Given their extremely low frequency of non-zero values, these features may be more effective when converted to:\n",
    "\n",
    "- `\"is_nonzero\"` binary flags  \n",
    "- rare-event indicators  \n",
    "- or categorical representations\n",
    "\n",
    "rather than treated as continuous numeric variables.\n",
    "\n",
    "---\n",
    "\n",
    "##### Key Insights\n",
    "The percentile analysis confirms that the dataset contains a mix of:\n",
    "\n",
    "- **dense continuous features** with long-tailed variability  \n",
    "- **sparse but informative event counters**  \n",
    "- **protocol usage indicators** where even small non-zero spikes carry semantic meaning  \n",
    "\n",
    "This combination reflects the heterogeneous nature of IoT network flows and highlights the importance of:\n",
    "\n",
    "- robust scaling methods  \n",
    "- careful handling of sparse features  \n",
    "- binary feature engineering  \n",
    "- and awareness of extreme values in downstream modeling.\n",
    "\n",
    "---\n",
    "\n",
    "##### Next Steps\n",
    "With univariate numeric analysis complete, we can now transition into **Bivariate Analysis**, examining how these features relate to the target `Label` and to each other. This will deepen our understanding of which numeric signals most strongly differentiate benign and malicious network activity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec337e",
   "metadata": {},
   "source": [
    "## 3. Bivariate Analysis\n",
    "\n",
    "The goal of our Bivariate Analysis section is two-fold.\n",
    "\n",
    "1. Assess relationships between numeric features and the target `Label` (different attack types vs benign) to identify strong predictors.\n",
    "2. How do numeric and catefgorical features relate to one another?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6879879",
   "metadata": {},
   "source": [
    "### 3.1 Numeric Features vs. Target Label\n",
    "\n",
    "#### 3.1.1 Percent Non-Zero Activation by Label\n",
    "\n",
    "Does this numeric feature activate more often in attacks traffic compared to benign traffic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df = (\n",
    "        scan\n",
    "        .group_by(\"Label\")\n",
    "        .agg([\n",
    "            (pl.col(col) == 0).sum().alias(\"zero_count\"),\n",
    "            (pl.col(col) != 0).sum().alias(\"nonzero_count\")\n",
    "        ])\n",
    "        .collect()\n",
    "        .to_pandas()\n",
    "    )\n",
    "\n",
    "    df[\"total\"] = df[\"zero_count\"] + df[\"nonzero_count\"]\n",
    "    df[\"pct_nonzero\"] = df[\"nonzero_count\"] / df[\"total\"] * 100\n",
    "    df[\"feature\"] = col\n",
    "\n",
    "    rows.append(df[[\"Label\", \"feature\", \"pct_nonzero\"]])\n",
    "\n",
    "# Combine into one big long-form table\n",
    "pct_nonzero_multiclass_df = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "pct_nonzero_multiclass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap visualization of non-zero percentages by label\n",
    "heatmap_df = pct_nonzero_multiclass_df.pivot(\n",
    "    index=\"Label\",\n",
    "    columns=\"feature\",\n",
    "    values=\"pct_nonzero\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(heatmap_df, cmap=\"viridis\")\n",
    "plt.title(\"Percent Non-Zero per Feature Across All Labels\")\n",
    "plt.ylabel(\"Label\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7ac1c",
   "metadata": {},
   "source": [
    "#### 3.1.1 Percent-Nonzero by Attack Category â€” Interpretation\n",
    "\n",
    "The heatmap above visualizes the percentage of non-zero values for every numeric feature across all 34 traffic categories (33 attack types + benign). This provides an activation â€œfingerprintâ€ for each attack type and illustrates which features are triggered more or less frequently under specific malicious behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. Clear Separation Between Benign and Attack Traffic\n",
    "The benign class shows a distinct non-zero activation pattern compared to nearly all attack types.  \n",
    "In particular:\n",
    "\n",
    "- Many protocol counters and flag-based features activate **more frequently in attacks**.  \n",
    "- Benign traffic tends to have **lower activation** across sparse features (e.g., `ack_flag_number`, `syn_flag_number`, `fmt_flag_number`, `psh_flag_number`, etc.).  \n",
    "- Several continuous features (e.g., `Rate`, `Tot_size`, `Variance`) show elevated activation in multiple attack types.\n",
    "\n",
    "This validates that network attacks produce characteristic shifts in feature activation patterns.\n",
    "\n",
    "---\n",
    "##### 2. Attack-Type Fingerprints Are Strongly Visible\n",
    "Different attack categories exhibit distinct activation signatures:\n",
    "\n",
    "- **Flooding attacks** (e.g., SYN flood, UDP flood, TCP flood) activate connection state flags (`syn_count`, `ack_count`, `rst_count`, etc.) at extremely high rates.\n",
    "- **Reconnaissance attacks** (e.g., portscan, pingsweep) show increased activation in features such as `Time_To_Live`, `Header_Length`, and certain protocol counters.\n",
    "- **Application-layer attacks** (e.g., slowloris, http flood) activate high-level protocol features (`HTTP`, `HTTPS`, `DNS`) more consistently.\n",
    "- **Backdoor and malware-related attacks** activate highly specific protocol counters that remain nearly unused in benign traffic.\n",
    "\n",
    "This demonstrates that each attack type produces a measurable and distinct pattern of protocol or flag activity.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Sparse Features Become Highly Informative\n",
    "Some features (e.g., `SSH`, `IRC`, `Telnet`, `SMTP`, `IGMP`, and several flag counters) show:\n",
    "\n",
    "- **Very low activation in benign traffic**\n",
    "- **High activation in certain attack types**\n",
    "\n",
    "These features behave like **rare-event binary indicators**, where even a small number of non-zero values strongly indicates malicious activity.\n",
    "\n",
    "This is valuable for downstream modeling, especially for tree-based classifiers and anomaly-oriented pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. Dense Features Also Discriminate Across Attack Families\n",
    "Continuous features such as:\n",
    "\n",
    "- `Rate`\n",
    "- `Std`\n",
    "- `Variance`\n",
    "- `Tot_size`\n",
    "\n",
    "exhibit noticeable differences in activation percentages across different attack categories.  \n",
    "These patterns suggest differences in throughput, packet timing, and burst behavior among various types of attacks.\n",
    "\n",
    "---\n",
    "\n",
    "##### Key Takeaways\n",
    "This heatmap demonstrates that **both sparse and dense numeric features vary significantly across attack types**, creating unique activation profiles for each class. These patterns will be highly valuable for:\n",
    "\n",
    "- feature engineering  \n",
    "- attack classification  \n",
    "- model explainability  \n",
    "- identifying discriminative signals for each class  \n",
    "\n",
    "This analysis sets a strong foundation for deeper bivariate analysis, including boxplots, violin plots, and class-conditional distribution comparisons.\n",
    "\n",
    "---\n",
    "\n",
    "##### Next Step\n",
    "Boxplots (log scale) of numeric features across attack categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b1612",
   "metadata": {},
   "source": [
    "#### 3.1.2 Boxplots of Numeric Features by Attack Category "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
